{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba29aca-fd1b-4547-a97c-60eaef83589c",
   "metadata": {},
   "source": [
    "<h1>Data preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d77bf3c-b5df-4459-8976-fef65750c63a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:48:22.123217Z",
     "iopub.status.busy": "2025-08-07T13:48:22.122854Z",
     "iopub.status.idle": "2025-08-07T13:48:33.644560Z",
     "shell.execute_reply": "2025-08-07T13:48:33.644018Z",
     "shell.execute_reply.started": "2025-08-07T13:48:22.123167Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, QuantileTransformer\n",
    "np.random.seed(42) \n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('data/dataset v1.csv')\n",
    "\n",
    "#Convert remaining_lease into numerical remaining_lease_years\n",
    "def convert_lease_to_years(lease_str):\n",
    "    if not isinstance(lease_str, str):\n",
    "        return np.nan\n",
    "    years = 0\n",
    "    months = 0\n",
    "    # Use regex to find numbers associated with 'year' and 'month'\n",
    "    year_match = re.search(r'(\\d+)\\s*year', lease_str)\n",
    "    month_match = re.search(r'(\\d+)\\s*month', lease_str)\n",
    "    if year_match:\n",
    "        years = int(year_match.group(1))\n",
    "    if month_match:\n",
    "        months = int(month_match.group(1))\n",
    "    # Return the total lease in years, or NaN if no parts were found\n",
    "    if years == 0 and months == 0:\n",
    "        return np.nan\n",
    "    return years + months / 12.0\n",
    "\n",
    "df['remaining_lease_years'] = df['remaining_lease'].apply(convert_lease_to_years)\n",
    "\n",
    "#Ordinally encoded storey_range by taking the in-between storeys (floors 01-03 becomes 2)\n",
    "floor_map = {'01 TO 03': 2,'04 TO 06': 5,'07 TO 09': 8,'10 TO 12': 11,'13 TO 15': 14,\n",
    "    '16 TO 18': 17,'19 TO 21': 20,'22 TO 24': 23,'25 TO 27': 26,'28 TO 30': 29,\n",
    "    '31 TO 33': 32,'34 TO 36': 35,'37 TO 39': 38,'40 TO 42': 41,'43 TO 45': 44,\n",
    "    '46 TO 48': 47,'49 TO 51': 50,}\n",
    "\n",
    "df['storey_ordinal'] = df['storey_range'].map(floor_map)\n",
    "\n",
    "#Create train test splits\n",
    "df.drop(columns=['Unnamed: 0','storey_range','street_name','remaining_lease','latitude','longitude','nearest_bus_stop','nearest_pei',\n",
    "                   'nearest_jc','nearest_kindergarten','nearest_primary_school','nearest_secondary_school','nearest_poly',\n",
    "                   'nearest_library','nearest_hospital','nearest_mall','nearest_mrt_station','nearest_sports_facility','nearest_hawker_centre'],inplace=True)\n",
    "X = df.drop(columns=['resale_price'])\n",
    "y = df['resale_price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Sampling using Sample Weights\n",
    "X_train['combined_feature'] = X_train['town'].astype(str) + '_' + \\\n",
    "                            X_train['flat_type'].astype(str) + '_' + \\\n",
    "                            X_train['flat_model'].astype(str)\n",
    "\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=X_train['combined_feature']  # The imbalanced feature we want to correct for\n",
    ")\n",
    "\n",
    "fit_params = {\n",
    "    'regressor__sample_weight': sample_weights\n",
    "}\n",
    "X_train.drop(columns=['combined_feature'],inplace=True)\n",
    "\n",
    "#One hot encode categorical columns and scale numerical columns by fit transforming on train data and transforming test data\n",
    "categorical_columns = ['town', 'flat_type', 'flat_model']\n",
    "numerical_columns = [\n",
    "    'floor_area_sqm', 'lease_commence_date',\n",
    "    'dist_bus_stop_m', 'dist_pei_m', 'dist_jc_m', 'dist_kindergarten_m',\n",
    "    'dist_primary_school_m', 'dist_secondary_school_m', 'dist_poly_m',\n",
    "    'dist_library_m', 'dist_mall_m', 'dist_hospital_m', 'dist_mrt_station_m',\n",
    "    'dist_sports_facility_m', 'dist_hawker_centre_m',\n",
    "    'remaining_lease_years','storey_ordinal',]\n",
    "\n",
    "\n",
    "numerical_columns = [col for col in numerical_columns if col in X_train.columns]\n",
    "categorical_columns = [col for col in categorical_columns if col in X_train.columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_columns)\n",
    "    ],\n",
    "    remainder='drop' \n",
    ")\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "#Scale y_train and y_test\n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "y_train_reshaped = y_train.values.reshape(-1, 1)\n",
    "y_train_scaled = scaler.fit_transform(y_train_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e7763-a717-446a-b68d-a1525d60f12d",
   "metadata": {},
   "source": [
    "<h1>Modelling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c2e273-e149-47b0-a1ae-afafe71f4e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:48:33.645625Z",
     "iopub.status.busy": "2025-08-07T13:48:33.645363Z",
     "iopub.status.idle": "2025-08-07T13:48:33.690653Z",
     "shell.execute_reply": "2025-08-07T13:48:33.690154Z",
     "shell.execute_reply.started": "2025-08-07T13:48:33.645606Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234b50e-401b-4c8d-8e61-8967face78ce",
   "metadata": {},
   "source": [
    "<h2>Decision Tree Regressor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54594ca2-1f1b-4179-90c4-09cfad5a9674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:49:07.079311Z",
     "iopub.status.busy": "2025-08-07T13:49:07.078965Z",
     "iopub.status.idle": "2025-08-07T13:50:36.973553Z",
     "shell.execute_reply": "2025-08-07T13:50:36.972860Z",
     "shell.execute_reply.started": "2025-08-07T13:49:07.079279Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning Decision Tree Regressor ---\n",
      "Displaying results for each hyperparameter combination:\n",
      "   param_max_depth  param_min_samples_split  param_min_samples_leaf      rmse  rank_test_score\n",
      "4             None                        5                       2  0.280880                1\n",
      "31              30                        5                       2  0.281161                2\n",
      "29              30                       10                       1  0.281333                3\n",
      "5             None                       10                       2  0.281411                4\n",
      "7             None                        5                       4  0.281475                5\n",
      "6             None                        2                       4  0.281475                5\n",
      "32              30                       10                       2  0.281484                7\n",
      "2             None                       10                       1  0.281503                8\n",
      "33              30                        2                       4  0.281667                9\n",
      "34              30                        5                       4  0.281667                9\n",
      "30              30                        2                       2  0.281727               11\n",
      "3             None                        2                       2  0.281878               12\n",
      "35              30                       10                       4  0.282098               13\n",
      "8             None                       10                       4  0.282130               14\n",
      "28              30                        5                       1  0.283072               15\n",
      "1             None                        5                       1  0.283661               16\n",
      "0             None                        2                       1  0.289801               17\n",
      "27              30                        2                       1  0.290470               18\n",
      "21              20                        2                       2  0.296604               19\n",
      "22              20                        5                       2  0.296825               20\n",
      "20              20                       10                       1  0.296851               21\n",
      "19              20                        5                       1  0.297679               22\n",
      "25              20                        5                       4  0.298349               23\n",
      "24              20                        2                       4  0.298349               23\n",
      "23              20                       10                       2  0.298515               25\n",
      "26              20                       10                       4  0.298921               26\n",
      "18              20                        2                       1  0.300005               27\n",
      "13              10                        5                       2  0.462876               28\n",
      "10              10                        5                       1  0.463055               29\n",
      "12              10                        2                       2  0.463056               30\n",
      "9               10                        2                       1  0.463093               31\n",
      "11              10                       10                       1  0.463223               32\n",
      "14              10                       10                       2  0.463695               33\n",
      "15              10                        2                       4  0.463912               34\n",
      "16              10                        5                       4  0.463912               34\n",
      "17              10                       10                       4  0.464094               36\n",
      "\n",
      "Best Decision Tree Params: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Tuned Decision Tree RMSE: 44610.0152\n",
      "Tuned Decision Tree MAE:  29701.0628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Tuning Decision Tree Regressor ---\")\n",
    "param_grid_tree = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "grid_search_tree = GridSearchCV(estimator=tree_model, param_grid=param_grid_tree,\n",
    "                                cv=3, n_jobs=-1, verbose=0, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search_tree.fit(X_train, y_train_scaled, sample_weight=sample_weights)\n",
    "\n",
    "cv_results_tree = pd.DataFrame(grid_search_tree.cv_results_)\n",
    "cv_results_tree['rmse'] = np.sqrt(-cv_results_tree['mean_test_score'])\n",
    "print(\"Displaying results for each hyperparameter combination:\")\n",
    "results_df_tree = cv_results_tree[['param_max_depth', 'param_min_samples_split', 'param_min_samples_leaf', 'rmse', 'rank_test_score']]\n",
    "print(results_df_tree.sort_values(by='rank_test_score'))\n",
    "\n",
    "best_tree_model = grid_search_tree.best_estimator_\n",
    "print(f\"\\nBest Decision Tree Params: {grid_search_tree.best_params_}\")\n",
    "\n",
    "y_pred_tree = best_tree_model.predict(X_test)\n",
    "y_pred_tree = scaler.inverse_transform(y_pred_tree.reshape(-1, 1))\n",
    "rmse_tree = np.sqrt(mean_squared_error(y_test, y_pred_tree))\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "print(f\"Tuned Decision Tree RMSE: {rmse_tree:.4f}\")\n",
    "print(f\"Tuned Decision Tree MAE:  {mae_tree:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf0b76-d0f4-4ff1-beff-b77308874aba",
   "metadata": {},
   "source": [
    "<h2>XGBoost</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aef6f3d-4dff-4a43-bf3a-abcc71234d8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:50:37.002779Z",
     "iopub.status.busy": "2025-08-07T13:50:37.002435Z",
     "iopub.status.idle": "2025-08-07T13:54:03.560725Z",
     "shell.execute_reply": "2025-08-07T13:54:03.559592Z",
     "shell.execute_reply.started": "2025-08-07T13:50:37.002752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning XGBoost Regressor ---\n",
      "Displaying results for each hyperparameter combination:\n",
      "    param_n_estimators  param_max_depth  param_learning_rate  param_subsample      rmse  rank_test_score\n",
      "22                 200                7                 0.10              0.7  0.220834                1\n",
      "23                 200                7                 0.10              1.0  0.223157                2\n",
      "10                 200                7                 0.05              0.7  0.263937                3\n",
      "20                 100                7                 0.10              0.7  0.267209                4\n",
      "11                 200                7                 0.05              1.0  0.267485                5\n",
      "21                 100                7                 0.10              1.0  0.267640                6\n",
      "18                 200                5                 0.10              0.7  0.272529                7\n",
      "19                 200                5                 0.10              1.0  0.275148                8\n",
      "6                  200                5                 0.05              0.7  0.338207                9\n",
      "16                 100                5                 0.10              0.7  0.339661               10\n",
      "17                 100                5                 0.10              1.0  0.340014               11\n",
      "7                  200                5                 0.05              1.0  0.341170               12\n",
      "8                  100                7                 0.05              0.7  0.341189               13\n",
      "9                  100                7                 0.05              1.0  0.341294               14\n",
      "14                 200                3                 0.10              0.7  0.364332               15\n",
      "15                 200                3                 0.10              1.0  0.370175               16\n",
      "4                  100                5                 0.05              0.7  0.422646               17\n",
      "5                  100                5                 0.05              1.0  0.425258               18\n",
      "12                 100                3                 0.10              0.7  0.439403               19\n",
      "2                  200                3                 0.05              0.7  0.440579               20\n",
      "3                  200                3                 0.05              1.0  0.441668               21\n",
      "13                 100                3                 0.10              1.0  0.443259               22\n",
      "1                  100                3                 0.05              1.0  0.517752               23\n",
      "0                  100                3                 0.05              0.7  0.518332               24\n",
      "\n",
      "Best XGBoost Params: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.7}\n",
      "Tuned XGBoost RMSE: 36039.0152\n",
      "Tuned XGBoost MAE:  26746.2575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Tuning XGBoost Regressor ---\")\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.7, 1.0]\n",
    "}\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb,\n",
    "                               cv=3, n_jobs=-1, verbose=0, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search_xgb.fit(X_train, y_train_scaled, sample_weight=sample_weights)\n",
    "\n",
    "cv_results_xgb = pd.DataFrame(grid_search_xgb.cv_results_)\n",
    "cv_results_xgb['rmse'] = np.sqrt(-cv_results_xgb['mean_test_score'])\n",
    "print(\"Displaying results for each hyperparameter combination:\")\n",
    "results_df_xgb = cv_results_xgb[['param_n_estimators', 'param_max_depth', 'param_learning_rate', 'param_subsample', 'rmse', 'rank_test_score']]\n",
    "print(results_df_xgb.sort_values(by='rank_test_score'))\n",
    "\n",
    "\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "print(f\"\\nBest XGBoost Params: {grid_search_xgb.best_params_}\")\n",
    "\n",
    "y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "y_pred_xgb = scaler.inverse_transform(y_pred_xgb.reshape(-1, 1))\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(f\"Tuned XGBoost RMSE: {rmse_xgb:.4f}\")\n",
    "print(f\"Tuned XGBoost MAE:  {mae_xgb:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2c838-ab8e-4c2c-9cb4-0de09b5ba531",
   "metadata": {},
   "source": [
    "<h2>Ridge Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e58049f-1cc2-40e0-9703-cc82fb5a9d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:54:03.603126Z",
     "iopub.status.busy": "2025-08-07T13:54:03.601460Z",
     "iopub.status.idle": "2025-08-07T13:54:06.509555Z",
     "shell.execute_reply": "2025-08-07T13:54:06.508779Z",
     "shell.execute_reply.started": "2025-08-07T13:54:03.603096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning Ridge Regressor ---\n",
      "Displaying results for each hyperparameter combination:\n",
      "   param_alpha      rmse  rank_test_score\n",
      "0          0.1  0.322375                1\n",
      "1          1.0  0.322375                2\n",
      "2         10.0  0.322422                3\n",
      "3         50.0  0.323364                4\n",
      "4        100.0  0.325697                5\n",
      "\n",
      "Best Ridge Params: {'alpha': 0.1}\n",
      "Tuned Ridge Regression RMSE: 52930.0944\n",
      "Tuned Ridge Regression MAE:  40473.0117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Tuning Ridge Regressor ---\")\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1.0, 10.0, 50.0, 100.0]\n",
    "}\n",
    "ridge_model = Ridge(random_state=42)\n",
    "grid_search_ridge = GridSearchCV(estimator=ridge_model, param_grid=param_grid_ridge,\n",
    "                                 cv=3, n_jobs=-1, verbose=0, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search_ridge.fit(X_train, y_train_scaled, sample_weight=sample_weights)\n",
    "\n",
    "cv_results_ridge = pd.DataFrame(grid_search_ridge.cv_results_)\n",
    "cv_results_ridge['rmse'] = np.sqrt(-cv_results_ridge['mean_test_score'])\n",
    "print(\"Displaying results for each hyperparameter combination:\")\n",
    "results_df_ridge = cv_results_ridge[['param_alpha', 'rmse', 'rank_test_score']]\n",
    "print(results_df_ridge.sort_values(by='rank_test_score'))\n",
    "\n",
    "\n",
    "best_ridge_model = grid_search_ridge.best_estimator_\n",
    "print(f\"\\nBest Ridge Params: {grid_search_ridge.best_params_}\")\n",
    "\n",
    "y_pred_ridge = best_ridge_model.predict(X_test)\n",
    "y_pred_ridge = scaler.inverse_transform(y_pred_ridge.reshape(-1, 1))\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "print(f\"Tuned Ridge Regression RMSE: {rmse_ridge:.4f}\")\n",
    "print(f\"Tuned Ridge Regression MAE:  {mae_ridge:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
