{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be074f98-3681-4d0e-ba04-92e0dd51d853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:01:04.269688Z",
     "iopub.status.busy": "2025-08-07T13:01:04.269272Z",
     "iopub.status.idle": "2025-08-07T13:01:04.274013Z",
     "shell.execute_reply": "2025-08-07T13:01:04.273209Z",
     "shell.execute_reply.started": "2025-08-07T13:01:04.269651Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df1249ea-2736-4833-a9f8-cfba8fd73557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:02:28.108392Z",
     "iopub.status.busy": "2025-08-07T13:02:28.107800Z",
     "iopub.status.idle": "2025-08-07T13:02:32.058836Z",
     "shell.execute_reply": "2025-08-07T13:02:32.057962Z",
     "shell.execute_reply.started": "2025-08-07T13:02:28.108324Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import numpy\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('data/dataset v1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784cce83-323d-4d36-ba82-5cc60b212ec7",
   "metadata": {},
   "source": [
    "<h2>Data preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40ce5e1a-199e-4b88-80e0-3e2293352dd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:02:32.067234Z",
     "iopub.status.busy": "2025-08-07T13:02:32.066601Z",
     "iopub.status.idle": "2025-08-07T13:02:33.221234Z",
     "shell.execute_reply": "2025-08-07T13:02:33.220328Z",
     "shell.execute_reply.started": "2025-08-07T13:02:32.067200Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_lease_to_years(lease_str):\n",
    "    if not isinstance(lease_str, str):\n",
    "        return np.nan\n",
    "    years = 0\n",
    "    months = 0\n",
    "    # Use regex to find numbers associated with 'year' and 'month'\n",
    "    year_match = re.search(r'(\\d+)\\s*year', lease_str)\n",
    "    month_match = re.search(r'(\\d+)\\s*month', lease_str)\n",
    "    if year_match:\n",
    "        years = int(year_match.group(1))\n",
    "    if month_match:\n",
    "        months = int(month_match.group(1))\n",
    "    # Return the total lease in years, or NaN if no parts were found\n",
    "    if years == 0 and months == 0:\n",
    "        return np.nan\n",
    "    return years + months / 12.0\n",
    "\n",
    "df['remaining_lease_years'] = df['remaining_lease'].apply(convert_lease_to_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0e2b4e8c-4b3a-4298-a88f-271f7c445c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:02:33.222772Z",
     "iopub.status.busy": "2025-08-07T13:02:33.222341Z",
     "iopub.status.idle": "2025-08-07T13:02:33.270590Z",
     "shell.execute_reply": "2025-08-07T13:02:33.269672Z",
     "shell.execute_reply.started": "2025-08-07T13:02:33.222745Z"
    }
   },
   "outputs": [],
   "source": [
    "floor_map = {'01 TO 03': 2,'04 TO 06': 5,'07 TO 09': 8,'10 TO 12': 11,'13 TO 15': 14,\n",
    "    '16 TO 18': 17,'19 TO 21': 20,'22 TO 24': 23,'25 TO 27': 26,'28 TO 30': 29,\n",
    "    '31 TO 33': 32,'34 TO 36': 35,'37 TO 39': 38,'40 TO 42': 41,'43 TO 45': 44,\n",
    "    '46 TO 48': 47,'49 TO 51': 50,}\n",
    "\n",
    "df['storey_ordinal'] = df['storey_range'].map(floor_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4c40c375-6a7e-4f64-a803-bd0b84fd01b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:02:33.272827Z",
     "iopub.status.busy": "2025-08-07T13:02:33.272152Z",
     "iopub.status.idle": "2025-08-07T13:02:33.353243Z",
     "shell.execute_reply": "2025-08-07T13:02:33.352323Z",
     "shell.execute_reply.started": "2025-08-07T13:02:33.272792Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','storey_range','street_name','remaining_lease','latitude','longitude','nearest_bus_stop','nearest_pei',\n",
    "                   'nearest_jc','nearest_kindergarten','nearest_primary_school','nearest_secondary_school','nearest_poly',\n",
    "                   'nearest_library','nearest_hospital','nearest_mall','nearest_mrt_station','nearest_sports_facility','nearest_hawker_centre'],inplace=True)\n",
    "X = df.drop(columns=['resale_price'])\n",
    "y = df['resale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a952e473-4961-4a38-bd9d-3e0cee5b874a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:02:33.358677Z",
     "iopub.status.busy": "2025-08-07T13:02:33.357706Z",
     "iopub.status.idle": "2025-08-07T13:02:33.460776Z",
     "shell.execute_reply": "2025-08-07T13:02:33.459852Z",
     "shell.execute_reply.started": "2025-08-07T13:02:33.358638Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb99b0-2c78-48f4-8eb5-838884fbed0a",
   "metadata": {},
   "source": [
    "<h2>Sample weights vs using pandas sample to create synthetic data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2ac7312-49d6-48b2-b3f4-b023d6e890f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:00:37.013576Z",
     "iopub.status.busy": "2025-08-07T13:00:37.013109Z",
     "iopub.status.idle": "2025-08-07T13:00:37.766948Z",
     "shell.execute_reply": "2025-08-07T13:00:37.766169Z",
     "shell.execute_reply.started": "2025-08-07T13:00:37.013546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions: [512911.11112935 551398.22642726 365799.86221968 747623.09993293\n",
      " 360417.22653039]\n",
      "MSE:  7967227787.7531\n",
      "RMSE: 89259.3289\n",
      "MAE:  71488.3163\n"
     ]
    }
   ],
   "source": [
    "# Sample weights\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# In your X_train DataFrame\n",
    "X_train['combined_feature'] = X_train['town'].astype(str) + '_' + \\\n",
    "                            X_train['flat_type'].astype(str) + '_' + \\\n",
    "                            X_train['flat_model'].astype(str)\n",
    "\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=X_train['combined_feature']  # The imbalanced feature we want to correct for\n",
    ")\n",
    "\n",
    "fit_params = {\n",
    "    'regressor__sample_weight': sample_weights\n",
    "}\n",
    "X_train.drop(columns=['combined_feature'],inplace=True)\n",
    "X_train.drop(columns=['month','town','flat_type','flat_model','block'],inplace=True)\n",
    "X_test.drop(columns=['month','town','flat_type','flat_model','block'],inplace=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"\\nSample Predictions: {y_pred[:5]}\")\n",
    "print(f\"MSE:  {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "print(f\"MAE:  {mean_absolute_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "43f68eaf-1e4b-4fa3-a493-fd7b61b9491c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:02:39.617417Z",
     "iopub.status.busy": "2025-08-07T13:02:39.616926Z",
     "iopub.status.idle": "2025-08-07T13:02:53.658786Z",
     "shell.execute_reply": "2025-08-07T13:02:53.657916Z",
     "shell.execute_reply.started": "2025-08-07T13:02:39.617378Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing 'town'. Target count for each category will be: 11313\n",
      "\n",
      "New data distribution for 'town':\n",
      "town\n",
      "JURONG EAST        11313\n",
      "KALLANG/WHAMPOA    11313\n",
      "PUNGGOL            11313\n",
      "TOA PAYOH          11313\n",
      "YISHUN             11313\n",
      "SENGKANG           11313\n",
      "HOUGANG            11313\n",
      "BEDOK              11313\n",
      "TAMPINES           11313\n",
      "BUKIT BATOK        11313\n",
      "WOODLANDS          11313\n",
      "ANG MO KIO         11313\n",
      "SEMBAWANG          11313\n",
      "JURONG WEST        11313\n",
      "BUKIT MERAH        11313\n",
      "CHOA CHU KANG      11313\n",
      "PASIR RIS          11313\n",
      "BUKIT PANJANG      11313\n",
      "QUEENSTOWN         11313\n",
      "BISHAN             11313\n",
      "SERANGOON          11313\n",
      "GEYLANG            11313\n",
      "CLEMENTI           11313\n",
      "CENTRAL AREA       11313\n",
      "BUKIT TIMAH        11313\n",
      "MARINE PARADE      11313\n",
      "Name: count, dtype: int64\n",
      "Balancing 'flat_type'. Target count for each category will be: 118602\n",
      "\n",
      "New data distribution for 'flat_type':\n",
      "flat_type\n",
      "3 ROOM              118602\n",
      "4 ROOM              118602\n",
      "5 ROOM              118602\n",
      "EXECUTIVE           118602\n",
      "2 ROOM              118602\n",
      "1 ROOM              118602\n",
      "MULTI-GENERATION    118602\n",
      "Name: count, dtype: int64\n",
      "Balancing 'flat_model'. Target count for each category will be: 275228\n",
      "\n",
      "New data distribution for 'flat_model':\n",
      "flat_model\n",
      "New Generation            275228\n",
      "Improved                  275228\n",
      "Premium Apartment         275228\n",
      "Model A                   275228\n",
      "Maisonette                275228\n",
      "Model A2                  275228\n",
      "Apartment                 275228\n",
      "Simplified                275228\n",
      "DBSS                      275228\n",
      "Standard                  275228\n",
      "Adjoined flat             275228\n",
      "Type S1                   275228\n",
      "2-room                    275228\n",
      "Premium Apartment Loft    275228\n",
      "Model A-Maisonette        275228\n",
      "Multi Generation          275228\n",
      "Improved-Maisonette       275228\n",
      "Terrace                   275228\n",
      "Type S2                   275228\n",
      "3Gen                      275228\n",
      "Premium Maisonette        275228\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample Predictions: [491327.96026811 592030.62867215 476568.12827217 820273.7444255\n",
      " 487886.5488451 ]\n",
      "MSE:  14097765363.7242\n",
      "RMSE: 118734.0110\n",
      "MAE:  96517.3783\n"
     ]
    }
   ],
   "source": [
    "#Using pandas sample to create synthetic data to balance out flat_type,flat_model and town\n",
    "import pandas as pd\n",
    "\n",
    "def balance_feature(df, column_name):\n",
    "    target_count = df[column_name].value_counts().max()\n",
    "    print(f\"Balancing '{column_name}'. Target count for each category will be: {target_count}\\n\")\n",
    "    \n",
    "    balanced_dfs_list = [df]\n",
    "    \n",
    "    for category, count in df[column_name].value_counts().items():\n",
    "        n_needed = target_count - count\n",
    "        if n_needed > 0:\n",
    "            subset = df[df[column_name] == category]\n",
    "            new_samples = subset.sample(n=n_needed, replace=True, random_state=42)\n",
    "            balanced_dfs_list.append(new_samples)\n",
    "            \n",
    "    balanced_df = pd.concat(balanced_dfs_list, ignore_index=True)\n",
    "    return balanced_df\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "# --- Balance by 'town' ---\n",
    "train_df = balance_feature(train_df, 'town')\n",
    "print(\"New data distribution for 'town':\")\n",
    "print(train_df['town'].value_counts())\n",
    "\n",
    "# --- Balance by 'flat_type' ---\n",
    "train_df = balance_feature(train_df, 'flat_type')\n",
    "print(\"New data distribution for 'flat_type':\")\n",
    "print(train_df['flat_type'].value_counts())\n",
    "\n",
    "# --- Balance by 'flat_model' ---\n",
    "train_df = balance_feature(train_df, 'flat_model')\n",
    "print(\"New data distribution for 'flat_model':\")\n",
    "print(train_df['flat_model'].value_counts())\n",
    "\n",
    "X_train = train_df.drop(columns=['resale_price'])\n",
    "y_train = train_df['resale_price']\n",
    "\n",
    "X_train.drop(columns=['month','town','flat_type','flat_model','block'],inplace=True)\n",
    "X_test.drop(columns=['month','town','flat_type','flat_model','block'],inplace=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"\\nSample Predictions: {y_pred[:5]}\")\n",
    "print(f\"MSE:  {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "print(f\"MAE:  {mean_absolute_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c326ec8-59fb-46cd-8fb9-f8913ee3d2d5",
   "metadata": {},
   "source": [
    "<h2>Resetting the training and test data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "943ce4ea-a554-4657-9ae1-2cfec595e2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:15:09.217290Z",
     "iopub.status.busy": "2025-08-07T13:15:09.216855Z",
     "iopub.status.idle": "2025-08-07T13:15:14.673319Z",
     "shell.execute_reply": "2025-08-07T13:15:14.672323Z",
     "shell.execute_reply.started": "2025-08-07T13:15:09.217239Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset v1.csv')\n",
    "\n",
    "def convert_lease_to_years(lease_str):\n",
    "    if not isinstance(lease_str, str):\n",
    "        return np.nan\n",
    "    years = 0\n",
    "    months = 0\n",
    "    # Use regex to find numbers associated with 'year' and 'month'\n",
    "    year_match = re.search(r'(\\d+)\\s*year', lease_str)\n",
    "    month_match = re.search(r'(\\d+)\\s*month', lease_str)\n",
    "    if year_match:\n",
    "        years = int(year_match.group(1))\n",
    "    if month_match:\n",
    "        months = int(month_match.group(1))\n",
    "    # Return the total lease in years, or NaN if no parts were found\n",
    "    if years == 0 and months == 0:\n",
    "        return np.nan\n",
    "    return years + months / 12.0\n",
    "\n",
    "df['remaining_lease_years'] = df['remaining_lease'].apply(convert_lease_to_years)\n",
    "\n",
    "floor_map = {'01 TO 03': 2,'04 TO 06': 5,'07 TO 09': 8,'10 TO 12': 11,'13 TO 15': 14,\n",
    "    '16 TO 18': 17,'19 TO 21': 20,'22 TO 24': 23,'25 TO 27': 26,'28 TO 30': 29,\n",
    "    '31 TO 33': 32,'34 TO 36': 35,'37 TO 39': 38,'40 TO 42': 41,'43 TO 45': 44,\n",
    "    '46 TO 48': 47,'49 TO 51': 50,}\n",
    "\n",
    "df['storey_ordinal'] = df['storey_range'].map(floor_map)\n",
    "\n",
    "df.drop(columns=['Unnamed: 0','storey_range','street_name','remaining_lease','latitude','longitude','nearest_bus_stop','nearest_pei',\n",
    "                   'nearest_jc','nearest_kindergarten','nearest_primary_school','nearest_secondary_school','nearest_poly',\n",
    "                   'nearest_library','nearest_hospital','nearest_mall','nearest_mrt_station','nearest_sports_facility','nearest_hawker_centre'],inplace=True)\n",
    "X = df.drop(columns=['resale_price'])\n",
    "y = df['resale_price']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c9dfad5-dceb-4d05-8b93-567c0727528f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:15:14.675246Z",
     "iopub.status.busy": "2025-08-07T13:15:14.674685Z",
     "iopub.status.idle": "2025-08-07T13:15:15.442935Z",
     "shell.execute_reply": "2025-08-07T13:15:15.441767Z",
     "shell.execute_reply.started": "2025-08-07T13:15:14.675209Z"
    }
   },
   "outputs": [],
   "source": [
    "# computing sample weights\n",
    "\n",
    "# In your X_train DataFrame\n",
    "X_train['combined_feature'] = X_train['town'].astype(str) + '_' + \\\n",
    "                            X_train['flat_type'].astype(str) + '_' + \\\n",
    "                            X_train['flat_model'].astype(str)\n",
    "\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=X_train['combined_feature']  # The imbalanced feature we want to correct for\n",
    ")\n",
    "\n",
    "fit_params = {\n",
    "    'regressor__sample_weight': sample_weights\n",
    "}\n",
    "X_train.drop(columns=['combined_feature'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d8272-f726-4230-a90f-099717203e05",
   "metadata": {},
   "source": [
    "<h2>Trying out different types of scalers for X_train and X_test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a3fefef6-f43d-4bab-b2c4-5c39a41cd1c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:21:01.576287Z",
     "iopub.status.busy": "2025-08-07T13:21:01.575543Z",
     "iopub.status.idle": "2025-08-07T13:21:14.606890Z",
     "shell.execute_reply": "2025-08-07T13:21:14.606115Z",
     "shell.execute_reply.started": "2025-08-07T13:21:01.576231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RMSE & MAE Comparison for Different Scalers ===\n",
      "StandardScaler\n",
      "Sample Predictions: [350746.85364092 602076.84831963 319797.66087859 852977.24556406\n",
      " 394380.98849884]\n",
      "MSE:  3894070274.5406\n",
      "RMSE: 62402.4861\n",
      "MAE:  48858.6420\n",
      "\n",
      "\n",
      "MinMaxScaler\n",
      "Sample Predictions: [350746.85364101 602076.84831972 319797.66087869 852977.24556415\n",
      " 394380.98849894]\n",
      "MSE:  3894070274.5414\n",
      "RMSE: 62402.4861\n",
      "MAE:  48858.6420\n",
      "\n",
      "\n",
      "RobustScaler\n",
      "Sample Predictions: [350746.85364093 602076.84831963 319797.6608786  852977.24556406\n",
      " 394380.98849885]\n",
      "MSE:  3894070274.5407\n",
      "RMSE: 62402.4861\n",
      "MAE:  48858.6420\n",
      "\n",
      "\n",
      "MaxAbsScaler\n",
      "Sample Predictions: [350746.85364744 602076.84832617 319797.6608851  852977.24557059\n",
      " 394380.98850535]\n",
      "MSE:  3894070274.5973\n",
      "RMSE: 62402.4861\n",
      "MAE:  48858.6420\n",
      "\n",
      "\n",
      "QuantileTransformer\n",
      "Sample Predictions: [287244.98119676 558089.88309541 276171.50452966 926569.30839539\n",
      " 482990.55023801]\n",
      "MSE:  6400347628.9980\n",
      "RMSE: 80002.1727\n",
      "MAE:  62856.0792\n",
      "\n",
      "\n",
      "PowerTransformer\n",
      "Sample Predictions: [371647.93677326 585607.93137738 308673.07143062 937536.04252561\n",
      " 482598.1866536 ]\n",
      "MSE:  7721520900.3306\n",
      "RMSE: 87872.1850\n",
      "MAE:  71445.9510\n",
      "\n",
      "\n",
      "Normalizer\n",
      "Sample Predictions: [364104.05225145 566079.10802957 312767.53126473 940262.49597281\n",
      " 457159.63023239]\n",
      "MSE:  7611099221.1357\n",
      "RMSE: 87241.6140\n",
      "MAE:  70385.7375\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler, \n",
    "    MaxAbsScaler, QuantileTransformer, PowerTransformer, Normalizer, OneHotEncoder\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "categorical_columns = ['town', 'flat_type', 'flat_model']\n",
    "numerical_columns = [\n",
    "    'floor_area_sqm', 'lease_commence_date',\n",
    "    'dist_bus_stop_m', 'dist_pei_m', 'dist_jc_m', 'dist_kindergarten_m',\n",
    "    'dist_primary_school_m', 'dist_secondary_school_m', 'dist_poly_m',\n",
    "    'dist_library_m', 'dist_mall_m', 'dist_hospital_m', 'dist_mrt_station_m',\n",
    "    'dist_sports_facility_m', 'dist_hawker_centre_m',\n",
    "    'remaining_lease_years','storey_ordinal',]\n",
    "\n",
    "# Define all scalers to compare\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler(),\n",
    "    'QuantileTransformer': QuantileTransformer(output_distribution='normal'),\n",
    "    'PowerTransformer': PowerTransformer(method='yeo-johnson'),\n",
    "    'Normalizer': Normalizer()\n",
    "}\n",
    "\n",
    "# Run comparison\n",
    "print(\"=== RMSE & MAE Comparison for Different Scalers ===\")\n",
    "\n",
    "for name, scaler in scalers.items():\n",
    "    # Build ColumnTransformer with current scaler\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', scaler, numerical_columns),\n",
    "            ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_columns)\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_preprocessed, y_train,sample_weight=sample_weights)\n",
    "    y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "    print(name)\n",
    "    print(f\"Sample Predictions: {y_pred[:5]}\")\n",
    "    print(f\"MSE:  {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "    print(f\"MAE:  {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1076f9-e0e0-469e-938a-f60690c7e372",
   "metadata": {},
   "source": [
    "<h2>Comparing different types of scalers on y_train and y_test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3dd20eb6-6e58-45ac-a857-d5aa66208bb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T13:28:27.797071Z",
     "iopub.status.busy": "2025-08-07T13:28:27.796028Z",
     "iopub.status.idle": "2025-08-07T13:28:34.129100Z",
     "shell.execute_reply": "2025-08-07T13:28:34.128370Z",
     "shell.execute_reply.started": "2025-08-07T13:28:27.797029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RMSE & MAE Comparison for Different Target Scalers ===\n",
      "\n",
      "--- Testing Scaler: StandardScaler ---\n",
      "RMSE: 62402.4861\n",
      "MAE:  48858.6420\n",
      "\n",
      "--- Testing Scaler: MinMaxScaler ---\n",
      "RMSE: 62402.4861\n",
      "MAE:  48858.6420\n",
      "\n",
      "--- Testing Scaler: RobustScaler ---\n",
      "RMSE: 62402.4861\n",
      "MAE:  48858.6420\n",
      "\n",
      "--- Testing Scaler: MaxAbsScaler ---\n",
      "RMSE: 62402.4861\n",
      "MAE:  48858.6420\n",
      "\n",
      "--- Testing Scaler: QuantileTransformer ---\n",
      "RMSE: 53045.4391\n",
      "MAE:  40592.8632\n",
      "\n",
      "--- Testing Scaler: PowerTransformer ---\n",
      "RMSE: 53859.3113\n",
      "MAE:  41205.3897\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler,\n",
    "    MaxAbsScaler, QuantileTransformer, PowerTransformer, OneHotEncoder\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define your feature columns\n",
    "categorical_columns = ['town', 'flat_type', 'flat_model']\n",
    "numerical_columns = [\n",
    "    'floor_area_sqm', 'lease_commence_date',\n",
    "    'dist_bus_stop_m', 'dist_pei_m', 'dist_jc_m', 'dist_kindergarten_m',\n",
    "    'dist_primary_school_m', 'dist_secondary_school_m', 'dist_poly_m',\n",
    "    'dist_library_m', 'dist_mall_m', 'dist_hospital_m', 'dist_mrt_station_m',\n",
    "    'dist_sports_facility_m', 'dist_hawker_centre_m',\n",
    "    'remaining_lease_years','storey_ordinal',]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_columns)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "# --- Define all scalers to compare for the target variable ---\n",
    "target_scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler(),\n",
    "    'QuantileTransformer': QuantileTransformer(output_distribution='normal'),\n",
    "    'PowerTransformer': PowerTransformer(method='yeo-johnson'),\n",
    "}\n",
    "\n",
    "print(\"=== RMSE & MAE Comparison for Different Target Scalers ===\")\n",
    "\n",
    "# --- Loop through each scaler, apply it to y, train, predict, and unscale ---\n",
    "for name, scaler in target_scalers.items():\n",
    "    print(f\"\\n--- Testing Scaler: {name} ---\")\n",
    "\n",
    "    # 1. Reshape y_train to be a 2D array for the scaler\n",
    "    y_train_reshaped = y_train.values.reshape(-1, 1)\n",
    "    y_test_reshaped = y_test.values.reshape(-1, 1)\n",
    "\n",
    "    # 2. Fit the scaler on y_train and transform both y_train and y_test\n",
    "    y_train_scaled = scaler.fit_transform(y_train_reshaped)\n",
    "    y_test_scaled = scaler.transform(y_test_reshaped) # Use transform only on test data\n",
    "\n",
    "    # 3. Train the model on the scaled target variable\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_preprocessed, y_train_scaled, sample_weight=sample_weights)\n",
    "    \n",
    "    # 4. Make predictions. The output will be on the scaled magnitude.\n",
    "    y_pred_scaled = model.predict(X_test_preprocessed)\n",
    "\n",
    "    # 5. IMPORTANT: Unscale the predictions back to the original price range\n",
    "    y_pred_unscaled = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # 6. Calculate metrics using the unscaled predictions and original y_test\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_unscaled))\n",
    "    mae = mean_absolute_error(y_test, y_pred_unscaled)\n",
    "    \n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE:  {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
